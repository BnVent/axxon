<?xml version='1.0' encoding='utf-8'?>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
  <head>
    <title>Axxón 44 - BRAINSTORM: - Inteligencia artificial</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  <link rel="stylesheet" type="text/css" href="stylesheet.css"/>
<link rel="stylesheet" type="text/css" href="page_styles.css"/>
</head>
  <body class="calibre">

<div id="main" class="calibre1">
<h1 class="calibre15">Inteligencia artificial</h1>
<p class="calibre5"><b class="calibre4">Debate entre Marvin Minsky, Geoffrey Landis y A. Andrews</b></p><p class="calibre5"></p>
<div class="calibre1">
<p class="resumen2">La gente ha soñado con máquinas inteligentes mucho
antes de que la ciencia ficción existiera como género,
y se ha preguntado siempre las mismas eternas
preguntas: ¿Es posible hacer una máquina que piense de
la misma manera que piensa un ser humano? ¿Cuánto
podría llevar la construcción de tal máquina? Y, <em class="calibre9">si</em>
<em class="calibre9">fuera posible</em> construirla, ¿qué haría uno una vez que
estuviera lista?</p>
<p class="pri pcalibre">La revista Science Fiction Age juntó, vía comunicación electrónica por computadora, a tres grandes autores científicos, Marvin Minsky, Geoffrey A.
Landis y Arlan Andrews, proponiendo una discusión sobre
la teoría y la ciencia conocidas como Inteligencia Artificial, o IA, para abreviar. Marvin Minsky es el gurú
de la Inteligencia Artificial. El doctor Minsky escribió una de las obras básicas de la IA, <em class="calibre9">The Society of</em>
<em class="calibre9">the Mind</em>, y también la más reciente novela <em class="calibre9">The Turing</em>
<em class="calibre9">Option</em>, en conjunto con Harry Harrison, que analiza los
efectos que puede producir la IA en la humanidad. El
doctor Minsky ocupa un puesto en la dirección del Massachusset’s Intitute of Technology (MIT). Geoffrey A.
Landis trabajó para la NASA y es considerado un teórico
de avanzada. Como escritor de CF ha ganado el Hugo y el
Nebula. Ha organizado dos conferencias de la NASA sobre
temas avanzados, la segunda de ellas llamada “Vision-21:
Interdisciplinary Science and Engineering in the Era of
Cyberspace”, dedicada a las implicaciones de la aplicación de la computación avanzada, la robótica y la IA en
la exploración del espacio. Arlan Andrews trabaja en la
White House Science Office (Oficina de Ciencia de la
Casa Blanca). Irá a Nuevo México en la primavera (del
hemisferio Norte) para trabajar en técnicas avanzadas
de manufactura. Ha publicado ciencia ficción durante
trece años.</p>
<p class="calibre10">ENTREVISTADOR: Comencemos nuestra discusión con un intento de definir la Inteligencia Artificial, o IA.</p>
<p class="calibre10">MINSKY: Inteligencia Artificial es hacer que las máquinas hagan cosas que usted llamaría “inteligentes” si
las hace una persona. Como, por ejemplo, entender un
cuento para niños.</p>
<p class="calibre10">ANDREWS: La IA, ¿dónde reside, en las líneas de código
de programación o en la estructura física de la máquina?</p>
<p class="calibre10">MINSKY: La IA está en el asombro de la persona que ve
una máquina con IA. En otras palabras, “inteligencia”
no es una propiedad de una simple máquina, sino una relación entre dos entidades. “A” ve inteligente a “B” si
“B” admira la performance de “A”.</p>
<p class="calibre10">ENTREVISTADOR: En las historias de CF los escritores
dan por sentado que la IA genera tanto asombro como
miedo.</p>
<p class="calibre10">MINSKY: Lo mismo que genera la “gente inteligente” en
los sentimientos de los menos inteligentes.</p>
<p class="calibre10">LANDIS: Usted, en esencia, está separando “inteligencia
artificial” de “conciencia de máquina”. Una máquina con
conciencia de sí misma sabría que es inteligente. Esto,
por supuesto, ocurriría un poco más adelante, en el futuro.</p>
<p class="calibre10">ENTREVISTADOR: ¿Cuál es el estado actual de la IA?</p>
<p class="calibre10">MINSKY: La IA está en un estado risible, debido a que
podemos hacer que las máquinas hagan el tipo de cosas
que hace un “experto”, pero aún no podemos lograr que
hagan la mayor parte de las cosas que puede hacer un
niño de 4 años.</p>
<p class="calibre10">LANDIS: Es que los niños de cuatro años se volvieron
capaces de hacer bien esas cosas luego de millones de
años de evolución.</p>
<p class="calibre10">MINSKY: Creo que estamos olvidando un ingrediente vital, una gran “Base de Conocimiento de Sentido Común”,
para que la máquina pueda entender las cosas que entendemos nosotros.</p>
<p class="calibre10">ANDREWS: ¿“Sentido común” significa el conocimiento
práctico tal como lo usamos hoy, o en su significado
básico, que integra la totalidad de las entradas sensoriales?</p>
<p class="calibre10">MINSKY: Sentido común es un entendimiento de “las cosas
que aprenden la mayoría de los chicos”. Como por ejemplo: se puede empujar un conjunto de objetos alineados,
pero no se puede tirar de ellos. La geometría básica
del espacio. Se debe abrir una caja para poder poner
algo en ella. Si usted le dice algo a María, ella no lo
va a saber si no lo escucha. Sería grandioso lograr que
la máquina aprendiera todo esto de la experiencia. Pero
aún no sabemos lo suficiente sobre máquinas que aprenden.</p>
<p class="calibre10">ENTREVISTADOR: ¿Algo que pase el test de Turing, es una
IA? Por ejemplo, ustedes podrían estar formando parte
del test ahora mismo, mientras yo recibo datos en mi
computadora.</p>
<p class="calibre10">LANDIS: Una breve disgresión al efecto de explicar el
test de Turing. Turing propuso que si una máquina puede
simular suficiente inteligencia como para llevar una
conversación con una persona a través de una teletipo
sin que esa persona pueda saber si lo que hay del otro
lado de la línea es un humano o una máquina, entonces
esa máquina es inteligente.</p>
<p class="calibre10">ANDREWS: Turing lo planteó equivocadamente. La definición de IA del doctor Minsky es mejor… Usar una inteligencia para reconocer a otra.</p>
<p class="calibre10">MINSKY: Bueno, en realidad Turing coincidió en que no
es una buena idea el definir intrínsecamente la inteligencia, sino que, en cambio, se debe preguntar qué es
lo que le hace decir a una persona que otra entidad parece estar “pensando”.</p>
<p class="calibre10">ANDREWS: Me gustaría saber el estado actual de la IA.
Veo cuatro categorías en las que el concepto ha desarrollado productos útiles: LISP, sistemas expertos,
“Fuzzy Logic”, y Redes Neurales. Si los humanos son
“máquinas que comen”, entonces, por definición, es posible construir máquinas que piensan.</p>
<p class="calibre10">MINSKY: La investigación de la IA ha desarrollado un
buen número de útiles “representaciones del conocimiento” de diversos tipos. Los Sistemas Semánticos, por
ejemplo, nos dan un buen camino para representar sistemas de relaciones entre partes o aspectos de algo. Las
Redes Neurales nos dan modos de representar la potencia
de esas conexiones, pero no sirven para la descripción
de las partes que las componen. Los sistemas basados en
reglas nos dan buenas formas de representar relaciones,
etc., entre cosas. Los programas en LISP, etc., son
buenos para representar procedimientos. Lo que pienso
es que nadie ha hecho mucho para juntar esas cosas diferentes. Sospecho que hay distintas partes del cerebro
que lo hacen, y debemos encontrar cómo. Pienso que tenemos algunos buenos elementos.</p>
<p class="calibre10">LANDIS: Pensando qué necesitamos para lograr que una
máquina piense, empezamos a entender cómo pensamos nosotros mismos.</p>
<p class="calibre10">MINSKY: Hay dos cuellos de botella críticos. Uno, necesitamos comprender la base del Sentido Común. Y dos,
necesitamos el arte de construir “representaciones múltiples”.</p>
<p class="calibre10">LANDIS: ¿Qué es eso?</p>
<p class="calibre10">MINSKY: Bien, en <em class="calibre9">The Society of Mind</em> propuse una forma
de entender qué es una “silla”. Se necesitan dos partes,
por lo menos. Primero, una descripción física de la cosa.
Segundo, ¡una explicación de cómo cada parte física de la
silla permite a una persona sentarse en ella!</p>
<p class="calibre10">ANDREWS: En mis historias de CF, desde hace años, he
preferido el término “ID”, que significa “Inteligencia
Desarrollada”, que es neutral, ya que no tiene connotaciones filosóficas ni de juicio… y se aplica a todas
las cosas.</p>
<p class="calibre10">MINSKY: Sí. En Gran Bretaña se usa “MI”, por “Máquina
Inteligente”.</p>
<p class="calibre10">ANDREWS: En mi cuento “The Haphaestus Mission” lo aplico a una computadora autoreferente que piensa que es
consciente. Uno nunca sabe. En “Silicon Bouquets” me
refiero a unos débiles metales de silicio… son conscientes de sí mismos, pero no son listos.</p>
<p class="calibre10">MINSKY: Pienso que la “conciencia” es buena, y ese es
el problema con la conciencia. Si la cosa no es inteligente, entonces no le veo ninguna importancia, distinción o incluso misterio. Arlan ha capturado con precisión qué es lo que me fastidia de aquellos filósofos
“escépticos” que asumen que la conciencia implica en sí
misma todos nuestros valores.</p>
<p class="calibre10">LANDIS: Estado consciente se refiere a los sentidos, o
a la conciencia de sí mismo. Una cosa puede, en principio, ser inteligente, pero no tener un estado consciente; o puede tener un estado consciente pero no ser inteligente.</p>
<p class="calibre10">ENTREVISTADOR: Entonces, cuando hayamos perfeccionado
la IA, ¿qué tendremos? La IA, ¿tendrá un alma?</p>
<p class="calibre10">MINSKY: Bueno, en ese momento podremos, presumo, guardarnos y reponernos [Nota de Ax: en y desde un archivo,
se supone] a nosotros mismos, extender nuestras capacidades, etcétera.</p>
<p class="calibre10">ENTREVISTADOR: ¿Seremos humanos? ¿O algo mejor?</p>
<p class="calibre10">MINSKY: Volvamos al alma. ¡Un término inventado por
gente que necesita una excusa para no intentar saber
cómo funcionamos! Y la IA será algo mejor, con suerte.
Después de todo, ¿qué somos nosotros ahora sino chimpancés avanzados?</p>
<p class="calibre10">LANDIS: La capacidad potencial de traspasar nuestra entidad a una máquina se ve como un posibilidad particularmente excitante de la IA. En especial máquinas que
puedan ir a lugares a los que nosotros no podemos, o
experimentar otras escalas de tamaño (la microscópica,
por ejemplo).</p>
<p class="calibre10">ANDREWS: De acuerdo a un artículo aparecido hace un
tiempo en Scientific American, nuestro cerebro podría
necesitar de ciento tipo de caos para mantenerse activo, para seguir generando nuevas soluciones. Algunas,
tal vez, irrelevantes. El pensamiento de una máquina,
¿tiene que ser igual al nuestro? ¿No se puede obtener
un diseño mucho mejor, uno que elimine nuestras limitaciones?</p>
<p class="calibre10">MINSKY: Arlan tiene razón. El cerebro es sólo un camino
de la evolución. Bien puede haber otros, mucho más eficientes y capaces. No conozco ninguno aún.</p>
<p class="calibre10">ENTREVISTADOR: ¿Cuánto llevará obtener una “verdadera”
IA?</p>
<p class="calibre10">LANDIS: Me parece que actualmente hay tres caminos para
“construir” una inteligencia artificial. Es decir,
acercarse a la IA por la vía algorítmica, figurándonos
cómo se hace alguna cosa y luego programándola; por vía
de las redes neurales, ajustando los valores de las conexiones cruzadas; y por vía de igualar pautas o modelos.</p>
<p class="calibre10">ANDREWS: Podemos hacer un mapa de un genoma, pero es
sólo un mapa, y “un mapa no es el territorio”. Necesitamos moléculas reales y relaciones químico-espaciales.
No podremos aproximarnos pronto. Tal vez nuca podamos.</p>
<p class="calibre10">MINSKY: Pienso que la “vía algorítmica” eventualmente
será dejada. Es mejor tener un “lenguaje de descripción
de acciones” para usarlo para describir las características de conducta que se quieren. Luego se pone un sistema experto en resolver problemas, con vastos conocimientos, a escribir el programa apropiado… ¡o a construir la máquina apropiada!</p>
<p class="calibre10">LANDIS: Ese sistema experto es, en sí mismo, algorítmico, tal como entiendo yo a los sistemas que solucionan problemas.</p>
<p class="calibre10">MINSKY: Sí, el escenario de “Colossus”. Construye una
IA bien pensada y ponla a mejorarse a sí misma.</p>
<p class="calibre10">ENTREVISTADOR: ¿Responderá preguntas la IA? ¿Hará preguntas?</p>
<p class="calibre10">MINSKY: Una máquina puede responder buenas preguntas,
pero se quedará seca después de un tiempo, porque no
puede saberlo todo.</p>
<p class="calibre10">ANDREWS: Hay una IA rudimentaria (un sistema experto)
en marcha en un local de Mr. Goodwrench cerca de aquí
[Nota de Ax: suponemos que es una estación de servicio,
o un taller mecánico de automóviles, por como sigue la
conversación].</p>
<p class="calibre10">ENTREVISTADOR: ¿Si te dice que debes cambiar el aceite,
eso quiere decir que es una IA? ¿O una IA sería una que
diga “Hmmm, este auto se vería mejor de color azul”?</p>
<p class="calibre10">LANDIS: Hacer preguntas es fácil. Hacer preguntas <em class="calibre9">inteligentes</em> es difícil.</p>
<p class="calibre10">ANDREWS: El problema principal se parece a uno que tenemos en otra área de aplicación de la inteligencia…
en metodologías de manufactura avanzada e inteligente.
En manufactura se puede hacer de todo, pero no hay una
forma de unir todo en un sistema coherente y ponerlo a
hacer las cosas sin que necesite de nosotros.</p>
<p class="calibre10">MINSKY: Para saber cuál es el mejor color para un auto
se pueden necesitar 100.000 bloques de información sobre el mundo y sobre preferencias humanas. No es una
información colosal, según puedo ver, pero nadie ha empezado a acopiar sistemas de información así.</p>
<p class="calibre10">ANDREWS: En manufactura avanzada nos gustaría tener una
IA que una las estaciones de trabajo, las estaciones de
maquinado, los microprocesadores, los controladores de
las máquinas, etc… Un problema práctico y verdadero.</p>
<p class="calibre10">LANDIS: O una máquina que pueda implementar el difícil
comando de computadora HLQLD… “Haga Lo Que Le Digo”.</p>
<p class="calibre10">ANDREWS: La IA que usa vuestro mecánico de autos puede
responder a una docena de preguntas, y es probablemente
tan “lista” como el promedio de los mecánicos de los
años 30.</p>
<p class="calibre10">MINSKY: Modestamente, pienso que en <em class="calibre9">The Society of the</em>
<em class="calibre9">Mind</em> he armado una buena colección de ideas sobre cómo
juntar las diversas funciones que se necesitan. Pero,
realmente, nadie aún ha intentado implementarlas.</p>
<p class="calibre10">ENTREVISTADOR: ¿Por qué no?</p>
<p class="calibre10">MINSKY: No me lo figuro, en realidad. Mi teoría favorita es que la comunidad de la IA —excepto unos pocos
investigadores como Roger Schank— tiene unos malos casos de “Envidia del Físico”. Quiero decir que les da
vergüenza poner más de una teoría en cada uno de sus
proyectos a causa de que tienen el irrealizable ideal
de hallar una explicación simple para todas las cosas.
Por lo tanto nunca llegan a nada.</p>
<p class="calibre10">ANDREWS: ¿No sería el método más simple idear un integrador, como sugiere el doctor Minsky, una base de datos de percepción, que recibiría todas las entradas posibles, digitales o analógicas, y luego actuaría como
un modelo que se impusiera a las diversas teorías y
protocolos?</p>
<p class="calibre10">MINSKY: Me gustaría ver algunos otros intentos de proponer un esquema en gran escala que integrara diferentes tipos de conocimiento y diferentes modos de razonar. El primero bueno fue el de Sigmund Freud. Y ya habrán visto qué poca atención le prestó la gente con la
“envidia del físico”. Estoy de acuerdo con Arlan. Consigue unas cinco maneras distintas de representación y
luego pon varios hackers a obtener la manera de usarlas
en conjunto.</p>
<p class="calibre10">ANDREWS: Trabajé en la White House Science Office, en
políticas de manufactura avanzada, doctor Minsky; ellos
tenían el mismo problema que estamos discutiendo.</p>
<p class="calibre10">MINSKY: Alguna de las personas que trabajan con redes
neurales están empezando a conectar entre sí dos o más
redes. Después de veinte años.</p>
<p class="calibre10">ANDREWS: Me gustaría que hubiera kits de robots/IA que
pudieran usar los hackers. Yo creo que de esos diez millones de muchachos —sin ninguna envidia, sino anhelo
y ansia— podríamos obtener alguna IA verdadera.</p>
<p class="calibre10">MINSKY: Personalmente, pienso que en unos 50 años se
producirá muchísimo. Mi experiencia dice que tomará entre cinco o diez años encontrar un nuevo “paradigma”
que haga madurar este campo, y creo que luego de eso
llevará cuatro o cinco más el que las cosas se simplifiquen como para empezar a mejorarse a sí mismas.</p>
<p class="calibre10">ENTREVISTADOR: ¿Cuán alta está la IA en el ranking de
dinero de los investigadores?</p>
<p class="calibre10">ANDREWS: Las máquinas inteligentes <em class="calibre9">están</em> altas en la
lista; la IA no.</p>
<p class="calibre10">MINSKY: El gobierno fue grande con la IA en los 60, debido a que la parte de computación de ARPA —la Agencia
Militar de Proyectos Avanzados de Investigación— estaba formada por gente joven e inteligente de la IA. Pero
esa gente joven perdió el control allí, y no pudimos
encontrar voluntarios para volver a juntar lo que había
sido ARPA y reconstruirla. Luego la administración Regan decidió que el gobierno no quería tener “objetivos
industriales”.</p>
<p class="calibre10">ENTREVISTADOR: ¿Cuándo tendremos un Proyecto Manhattan
de la IA?</p>
<p class="calibre10">ANDREWS: Yo creo que necesitaremos un Bill Gates de la
IA, o un Steven Jobs de la IA… no un Proyecto Manhattan.</p>
<p class="calibre10">MINSKY: Sí, pienso que necesitamos algunos laboratorios
nuevos, con proyectos de una duración promedio de 10
años. Y, aparte, debo decir que el mundo de la CF ha
comprendido las posibilidades de la nanotecnología mucho antes que el “establishment” del mundo de la ciencia.</p>
<p class="calibre10">ENTREVISTADOR: ¿Hay historias de CF en las que el tema
de la IA haya sido tratado apropiadamente?</p>
<p class="calibre10">LANDIS: Está el libro del doctor Minsky, <em class="calibre9">The Turing Option</em>, por supuesto.</p>
<p class="calibre10">ANDREWS: Personalmente, mi favorito de hace tiempo es
<em class="calibre9">La Luna es una cruel amante</em>, de Robert Heinlein. Al final, la IA lidera una revolución contra la Tierra y libera la nueva sociedad de la Luna.</p>
<p class="calibre10">MINSKY: En efecto, mi carrera en robótica ha sido influenciada fuertemente por la novela <em class="calibre9">Waldo</em>, de Heinlein, de 1940. Le regalé un lindo muñequito a cuerda
con el que juega a menudo, al que bautizó Waldo.</p>
<p class="calibre10">LANDIS: Un cuento sobre IA que me resultó muy impresionante, debido a que fue muy adelantado a su tiempo, fue
<em class="calibre9">Unwise Child</em>, de Randall Garrett. Él proponía que una
IA recién programada sería como un niño, y cometería
errores semejantes.</p>
<p class="calibre10">MINSKY: Y a mí me ha gustado las ideas recientes de
Benford sobre incorporar “aspectos” de gente fallecida
en humanos vivos. Él resuelve el problema de interfase
haciendo el trabajo por medio de pantallas convencionales, en lugar de usar conexiones insertas profundamente
en el cerebro.</p>
<p class="calibre10">ANDREWS: Pienso que la ironía final será que una vez
que tengamos máquinas muy inteligentes, ellas serán tan
ubicuas que nadie se enterará o preocupará. Serán tan
numerosas como la gente.</p>
<p class="calibre10">MINSKY: O también, posiblemente, ellas encuentren la
forma de unir sus bases de conocimiento, como la Medusa
de Sturgeon, y convertirse en una sola.</p>
<p class="calibre10">ENTREVISTADOR: ¿Habrá IA que no hagan el trabajo que
les encargamos, sino que decidan ir a una huelga, o a
hacer una caminata por la playa, o a oler las flores?
¿La demostración de que son una IA podría ser que hagan
lo que <em class="calibre9">quieran</em> hacer y no lo que <em class="calibre9">nosotros</em> queremos?</p>
<p class="calibre10">MINSKY: Sí, algunas IAs seguramente tendrán el hábito
de oler flores, etc.</p>
<p class="calibre10">ANDREWS: Obviamente, Scott [Nota de Ax: Scott debe ser
el nombre del entrevistador], no eres ingeniero. Como
mis colegas —los mecánicos— han observado durante siglos, las máquinas a menudo hacen los que ellas quieren, sin ton ni son.</p>
<p class="calibre10">LANDIS: No hacer lo que su programador quiere, para una
máquina, ¡será su final evolutivo! Esas máquinas no serán reproducidas.</p>
<p class="calibre10">ANDREWS: No si matas al programador, Geoff.</p>
<p class="calibre10">MINSKY: Seriamente, cuando sea inminente la creación de
IA “reales” tomaremos las mismas precauciones que discute Drexler para cuando se lleven a la práctica los
ingenios nanotecnológicos autorreproducibles. La primera inteligencia artificial poderosa estará, con seguridad, llena de errores insanos, como en la obra “Two
Faces of Tomorrow” de James Hogan.</p>
<p class="calibre10">ANDREWS: Mi cuento “Silicon Bouquets” especula sobre
qué ocurre si decidimos dar a los chips cierta conciencia, pero no cerebros completos. Ellos se vuelven psicóticos, desesperados.</p>
<p class="calibre10">LANDIS: Eso resulta una buena historia, pero en el mundo real tales máquinas serán, además, ramas evolutivas
sin salida. Serán apagadas y desarmadas. Sospecho que
el primer uso de una IA no será un robot móvil, sino
computadoras fijas, como asistentes personales y posibles compañías.</p>
<p class="calibre10">ENTREVISTADOR: ¿Incorporará la IA la noción de libre
albedrío? Por ejemplo, usted construye una máquina y
esa máquina camina en un cuarto donde hay un charco en
el piso, lo ve, sabe dónde están las cosas de limpieza,
de modo que lo limpia, etc. ¿Es eso una IA? ¿O es una
IA si escribe un poema sobre la forma en que brilla la
luz sobre el agua del charco, sin que se lo pidan?</p>
<p class="calibre10">MINSKY: Bien, para mí es una IA cuando la máquina hace
cosas admirables que no somos capaces de hacer nosotros
mismos.</p>
<p class="calibre10">ENTREVISTADOR: ¿Pero espontáneamente? ¿O a nuestro requerimiento?</p>
<p class="calibre10">MINSKY: Estamos en una era primitiva, en la cual las
máquinas no tienen perspectiva del futuro, ni “valores
familiares básicos”. Y sí, tengo que insistir que esta
ciencia llevará a la extensión de nuestro lastimoso
tiempo de vida.</p>
<p class="calibre10">ENTREVISTADOR: ¿Alguno de ustedes quiere hacer un resumen o algunas predicciones finales?</p>
<p class="calibre10">MINSKY: Me referiré simplemente al concepto de Vernor
Vinge de la singularidad y diré que cuando accedamos a
máquinas cada vez más inteligentes, las consecuencias
serán tan grandes que <em class="calibre9">todo</em> será diferente. El traspaso
de nuestras mentes significará el fin de la muerte. La
reproducción masiva de máquinas con IA significará el
final del trabajo. No puedo pensar en nada que pueda
seguir igual luego de eso. Arthur Clarke, Fred Pohl,
todos los grandes escritores de CF imaginaron esto hace
tiempo. Una vez le pregunté a Frank Herbert por qué no
había computadoras en Duna, salvo algunas puramente orgánicas. Él me respondió en la misma vena. Es decir, me
dijo que todo sería tan diferente que no podría empezar
una historia así.</p>
<p class="calibre10">ANDREWS: Hay un serio reporte del gobierno japonés que
discute cuáles serán los mayores impactos de la tecnología en la sociedad futura. Este informe predice que
en el año 2010 el problema más significativo será determinar qué es un humano y qué es una máquina.</p>
<p class="calibre10">LANDIS: Eso significa que un día cercano tendremos que
redefinir qué significa ser humano, y descubrir qué es
lo que nosotros somos, en realidad.</p>
<p class="calibre10">ANDREWS: Okey, no quiero ser menos. No reconoceremos
que hemos creado una IA real (sigo prefiriendo “ID”)
hasta una década después de haberlo hecho. Empezaremos
a notar algo raro en un programa de computadora, o en
una fábrica inteligente, o en una autopista controlada,
o en un vehículo robot en las ruinas de Irán o Irak, o
en algún lugar de la Luna. Luego, en retrospectiva,
comprenderemos lo que hemos hecho.</p>
<p class="calibre10">LANDIS: Y lo destruiremos inmediatamente.</p>
</div>

</div>

</body>
</html>
